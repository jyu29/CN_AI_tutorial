{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd43cf1",
   "metadata": {},
   "source": [
    "The feedback about movies falls into one of two categories:\n",
    "\n",
    "- `Explicit`— users specify how much they liked a particular movie by providing a numerical rating.\n",
    "- `Implicit`— if a user watches a movie, the system infers that the user is interested.\n",
    "\n",
    "he data contain user_id, item_id, and interaction (0-non-interact, 1 – has interact). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7212906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(100000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 100 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df1b41",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9abdd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import time\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Embedding, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.initializers import RandomUniform, he_normal,he_uniform\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13111464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7c6d16",
   "metadata": {},
   "source": [
    "## read original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9de1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens_data(data_directory):\n",
    "    ratings_df = pd.read_csv(\n",
    "    os.path.join(data_directory, \"ratings.dat\"),\n",
    "    sep=\"::\",\n",
    "    names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine=\"python\")\n",
    "    movies_df = pd.read_csv(\n",
    "      os.path.join(data_directory, \"movies.dat\"),\n",
    "      sep=\"::\",\n",
    "      names=[\"MovieID\", \"Title\", \"Genres\"], engine=\"python\")\n",
    "\n",
    "  # Create dictionaries mapping from old IDs to new (remapped) IDs for both\n",
    "  # MovieID and UserID. Use the movies and users present in ratings_df to\n",
    "  # determine the mapping, since movies and users without ratings are unneeded.\n",
    "    movie_mapping = {\n",
    "      old_movie: new_movie for new_movie, old_movie in enumerate(\n",
    "          ratings_df.MovieID.astype(\"category\").cat.categories)\n",
    "  }\n",
    "    user_mapping = {\n",
    "      old_user: new_user for new_user, old_user in enumerate(\n",
    "          ratings_df.UserID.astype(\"category\").cat.categories)\n",
    "  }\n",
    "\n",
    "  # Map each DataFrame consistently using the now-fixed mapping.\n",
    "    ratings_df.MovieID = ratings_df.MovieID.map(movie_mapping)\n",
    "    ratings_df.UserID = ratings_df.UserID.map(user_mapping)\n",
    "    movies_df.MovieID = movies_df.MovieID.map(movie_mapping)\n",
    "\n",
    "  # Remove nulls resulting from some movies being in movies_df but not\n",
    "  # ratings_df.\n",
    "    movies_df = movies_df[pd.notnull(movies_df.MovieID)]\n",
    "\n",
    "    return ratings_df, movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c7d0ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101512</th>\n",
       "      <td>675</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>975685011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220535</th>\n",
       "      <td>1335</td>\n",
       "      <td>689</td>\n",
       "      <td>4</td>\n",
       "      <td>974946138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID  MovieID  Rating  Timestamp\n",
       "101512     675      344       2  975685011\n",
       "220535    1335      689       4  974946138"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = '/data/jyu29/data/recommendation_data'\n",
    "ratings_df, movies_df = load_movielens_data(data_directory)\n",
    "ratings_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e9b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.sparse.coo_matrix((ratings_df.rating, (ratings_df.userId, ratings_df.movieId)))\n",
    "ratings_df = ratings_df.rename(columns={\"UserID\":'userId','MovieID':'movieId','Rating':'rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afece9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823ef6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c323683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c45b6c0",
   "metadata": {},
   "source": [
    "## negative sampleing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76cdb5",
   "metadata": {},
   "source": [
    "metimes, we want to reduce the training time by using a subset of a very large dataset while the negative samples outnumbers the positive ones, e.g. word embedding. Another situation when we deal with implicit data. In this case, we may need to populate new data for negative values. This post demonstrates how to generate data for training using uniform negative sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65072a",
   "metadata": {},
   "source": [
    "If we consider interaction has value 1 and 0 otherwise, then the original rating data will become all 1s. So, you can see that with only 1s in the label, the model cannot distinguish between interact and not interact as shown in the following tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd230385",
   "metadata": {},
   "source": [
    "scipy.sparse.coo_matrix((ratings_df.rating, (ratings_df.userId, ratings_df.movieId)))We want to get n negative samples per one positive. The naive method can be:\n",
    "\n",
    "Loop through all user ids\n",
    "For each user id, get a random item id and check if the pair user-item does not exist in the dataset\n",
    "Add the found user-item as a negative sample to the dataset.\n",
    "If you follow these steps, then you may find the execution times can be really long (~20 mins). To accelerate the result, we utilize some useful libraries as follows:\n",
    "\n",
    "Generate a dense matrix from the dataset using scipy,\n",
    "rows and cols are users and items\n",
    "For each row, extract krandom items’ indices of 0 values using random.samples\n",
    "k is the number of non zero values in that row.\n",
    "Append the list of user-item from k extract index and append to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720c9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "438cda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"version 1.2: 1 positive 1 neg (2 times bigger than the original dataset by default)\n",
    "    Parameters:\n",
    "    input rating data as pandas dataframe: userId|movieId|rating\n",
    "    n_neg: take n_negative / 1 positive\n",
    "    Returns:\n",
    "    negative sampled set as pandas dataframe\n",
    "            userId|movieId|interact (implicit)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def neg_sampling(ratings_df, n_neg=1, neg_val=0, pos_val=1, percent_print=5):\n",
    "    ratings_df.userId = ratings_df.userId.astype('category').cat.codes.values\n",
    "    ratings_df.movieId = ratings_df.movieId.astype('category').cat.codes.values\n",
    "    sparse_mat = scipy.sparse.coo_matrix((ratings_df.rating, (ratings_df.userId, ratings_df.movieId)))\n",
    "    dense_mat = np.asarray(sparse_mat.todense())\n",
    "    print(dense_mat.shape)\n",
    "    \n",
    "    nsamples = ratings_df[['userId', 'movieId']]\n",
    "    nsamples['interact'] = nsamples.apply(lambda row: 1, axis=1)\n",
    "    length = dense_mat.shape[0]\n",
    "    printpc = int(length * percent_print/100)\n",
    "    nTempData = []\n",
    "    i = 0\n",
    "    start_time = time.time()\n",
    "    stop_time = time.time()\n",
    "    extra_samples = 0\n",
    "    for row in dense_mat:\n",
    "        if(i%printpc==0):\n",
    "            stop_time = time.time()\n",
    "#             print(\"processed ... {0:0.2f}% ...{1:0.2f}secs\".format(float(i)*100 / length, stop_time - start_time))\n",
    "            start_time = stop_time\n",
    "        n_non_0 = len(np.nonzero(row)[0])\n",
    "        zero_indices = np.where(row==0)[0]\n",
    "        \n",
    "        if(n_non_0 * n_neg + extra_samples > len(zero_indices)):\n",
    "            print(i, \"non 0:\", n_non_0,\": len \",len(zero_indices))\n",
    "            neg_indices = zero_indices.tolist()\n",
    "            extra_samples = n_non_0 * n_neg + extra_samples - len(zero_indices)\n",
    "        else:\n",
    "            neg_indices = random.sample(zero_indices.tolist(), n_non_0 * n_neg + extra_samples)\n",
    "            extra_samples = 0\n",
    "            nTempData.extend([(uu, ii, rr) for (uu, ii, rr) in zip(np.repeat(i, len(neg_indices))\n",
    "                    , neg_indices, np.repeat(neg_val, len(neg_indices)))])\n",
    "    i+=1\n",
    "    nsamples=nsamples.append(pd.DataFrame(nTempData, columns=[\"userId\",\"movieId\", \"interact\"]),ignore_index=True)\n",
    "    return nsamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67e409e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 3706)\n",
      "0 non 0: 2314 : len  1392\n"
     ]
    }
   ],
   "source": [
    "implicit_feedback_data = neg_sampling(ratings_df, n_neg=1, neg_val=0, pos_val=1, percent_print=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "935ad424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>interact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1225953</th>\n",
       "      <td>0</td>\n",
       "      <td>3014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872976</th>\n",
       "      <td>0</td>\n",
       "      <td>1964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499894</th>\n",
       "      <td>3068</td>\n",
       "      <td>1478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597005</th>\n",
       "      <td>3625</td>\n",
       "      <td>3521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384244</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  interact\n",
       "1225953       0     3014         0\n",
       "1872976       0     1964         0\n",
       "499894     3068     1478         1\n",
       "597005     3625     3521         1\n",
       "1384244       0       27         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_feedback_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08665562",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_feedback_data.to_csv('/data/jyu29/data/recommendation_data/implicit_feedback_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215f73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54bac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18a3d184",
   "metadata": {},
   "source": [
    "# read explicit feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74557635",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/data/jyu29/data/recommendation_data/implicit_feedback_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ddc4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename(columns={'userId':'user_id',\n",
    "                                 'movieId':'item_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5109bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "n_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n",
    "n_latent_factors = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebe52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d8a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be6a9a1c",
   "metadata": {},
   "source": [
    "# build mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22b93d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie input and embedding\n",
    "embedding_init = 'he_uniform'\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies, n_latent_factors,\n",
    "                                          embeddings_initializer=embedding_init,\n",
    "                                          embeddings_regularizer=l2(1e-6),\n",
    "                                          embeddings_constraint='NonNeg',\n",
    "                                          name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "#user input and embedding\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = keras.layers.Embedding(n_users, n_latent_factors,\n",
    "                                          embeddings_initializer=embedding_init,\n",
    "                                          embeddings_regularizer=l2(1e-6),\n",
    "                                          embeddings_constraint='NonNeg',\n",
    "                                          name='User-Embedding')(user_input)\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ca0c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Item (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " User (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Movie-Embedding (Embedding)    (None, 1, 50)        185300      ['Item[0][0]']                   \n",
      "                                                                                                  \n",
      " User-Embedding (Embedding)     (None, 1, 50)        302000      ['User[0][0]']                   \n",
      "                                                                                                  \n",
      " FlattenMovies (Flatten)        (None, 50)           0           ['Movie-Embedding[0][0]']        \n",
      "                                                                                                  \n",
      " FlattenUsers (Flatten)         (None, 50)           0           ['User-Embedding[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 100)          0           ['FlattenMovies[0][0]',          \n",
      "                                                                  'FlattenUsers[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           6464        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64)          256         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           2080        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 16)           528         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            17          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 496,645\n",
      "Trainable params: 496,517\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "concat = keras.layers.concatenate([movie_vec, user_vec])\n",
    "mlp = concat\n",
    "for i in range(3,-1,-1):\n",
    "    if i == 0:\n",
    "        mlp = Dense(8**i, activation='sigmoid', kernel_initializer='glorot_normal',\n",
    "                  name=\"output\")(mlp)\n",
    "    else:\n",
    "        mlp = Dense(8*2**i, activation='relu', kernel_initializer='he_uniform')(mlp)\n",
    "        if i > 2:\n",
    "            mlp = BatchNormalization()(mlp)\n",
    "            mlp = Dropout(0.2)(mlp)\n",
    "model = Model(inputs=[user_input, movie_input], outputs=[mlp])\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096854cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7728d45",
   "metadata": {},
   "source": [
    "## data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d5b8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, batch_size=16, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.dataframe = dataframe\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = dataframe.index\n",
    "        print(len(self.indices))\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return math.floor(len(self.dataframe) / self.batch_size)\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        idxs = [i for i in range(index*self.batch_size,(index+1)*self.batch_size)]\n",
    "        #print(idxs)\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.indices[k] for k in idxs]\n",
    "        # Generate data\n",
    "        User = self.dataframe.iloc[list_IDs_temp,[0]].to_numpy().reshape(-1)\n",
    "        Item = self.dataframe.iloc[list_IDs_temp,[1]].to_numpy().reshape(-1)\n",
    "        rating = self.dataframe.iloc[list_IDs_temp,[2]].to_numpy().reshape(-1)\n",
    "        #print(\"u,i,r:\", [User, Item],[y])\n",
    "        return [User, Item],[rating]\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indices = np.arange(len(self.dataframe))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b2365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f77f0a3",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb6f91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599220\n",
      "399806\n"
     ]
    }
   ],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_output_loss', min_delta = 0.0001, patience=10)\n",
    "traindatagenerator = DataGenerator(train)\n",
    "val_generator = DataGenerator(test)\n",
    "# history = model.fit(traindatagenerator, validation_data=val_generator, epochs=200, verbose=2, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3d57128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99951/99951 [==============================] - 426s 4ms/step - loss: 0.0371 - binary_accuracy: 0.9976 - val_loss: 4.3709e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "99951/99951 [==============================] - 431s 4ms/step - loss: 0.0011 - binary_accuracy: 0.9999 - val_loss: 4.4422e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "99951/99951 [==============================] - 440s 4ms/step - loss: 7.6047e-04 - binary_accuracy: 0.9999 - val_loss: 4.8007e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "99951/99951 [==============================] - 415s 4ms/step - loss: 6.0043e-04 - binary_accuracy: 1.0000 - val_loss: 4.9763e-04 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "99951/99951 [==============================] - 410s 4ms/step - loss: 6.4766e-04 - binary_accuracy: 1.0000 - val_loss: 5.2456e-04 - val_binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(traindatagenerator, validation_data=val_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d856dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
